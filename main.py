import io
import unicodedata
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import streamlit as st


# =============================
# Page config + Korean font
# =============================
st.set_page_config(page_title="ê·¹ì§€ì‹ë¬¼ ìµœì  EC ë†ë„ ì—°êµ¬", layout="wide")

st.markdown(
    """
<style>
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR&display=swap');
html, body, [class*="css"] {
    font-family: 'Noto Sans KR', 'Malgun Gothic', sans-serif;
}
</style>
""",
    unsafe_allow_html=True,
)

PLOTLY_FONT_FAMILY = "Malgun Gothic, Apple SD Gothic Neo, Noto Sans KR, sans-serif"


# =============================
# Constants
# =============================
SCHOOLS: List[str] = ["ì†¡ë„ê³ ", "í•˜ëŠ˜ê³ ", "ì•„ë¼ê³ ", "ë™ì‚°ê³ "]

# ì´ë²ˆ ìš”ì²­ ê¸°ì¤€ EC ì¡°ê±´ (ë³€ê²½ ë°˜ì˜)
SCHOOL_EC_TARGET: Dict[str, float] = {
    "ë™ì‚°ê³ ": 1.0,
    "ì†¡ë„ê³ ": 2.0,
    "í•˜ëŠ˜ê³ ": 4.0,  # (ìµœì ) ê°€ì„¤/ê¸°ëŒ€ì¹˜ë¡œ í‘œê¸°
    "ì•„ë¼ê³ ": 8.0,
}

# ìƒìœ¡ ì‹œíŠ¸ë³„ ê°œì²´ìˆ˜(ìš”ì•½ í‘œì— ì‚¬ìš©)
SCHOOL_N_EXPECTED: Dict[str, int] = {"ë™ì‚°ê³ ": 58, "ì†¡ë„ê³ ": 29, "ì•„ë¼ê³ ": 106, "í•˜ëŠ˜ê³ ": 45}

SCHOOL_COLOR: Dict[str, str] = {
    "ë™ì‚°ê³ ": "#1f77b4",
    "ì†¡ë„ê³ ": "#ff7f0e",
    "í•˜ëŠ˜ê³ ": "#2ca02c",
    "ì•„ë¼ê³ ": "#d62728",
}

ENV_REQUIRED_COLS = ["time", "temperature", "humidity", "ph", "ec"]
GROW_REQUIRED_COLS = ["ê°œì²´ë²ˆí˜¸", "ì ìˆ˜(ì¥)", "ì§€ìƒë¶€ ê¸¸ì´(mm)", "ì§€í•˜ë¶€ê¸¸ì´(mm)", "ìƒì¤‘ëŸ‰(g)"]


# =============================
# NFC/NFD safe filename match
# =============================
def _nfc(s: str) -> str:
    return unicodedata.normalize("NFC", s)


def _nfd(s: str) -> str:
    return unicodedata.normalize("NFD", s)


def _same_filename(a: str, b: str) -> bool:
    """
    NFC/NFD ì–‘ë°©í–¥ ë¹„êµ (í•„ìˆ˜ ìš”êµ¬ì‚¬í•­)
    """
    return len({_nfc(a), _nfd(a)}.intersection({_nfc(b), _nfd(b)})) > 0


def find_file_by_exact_names(folder: Path, exact_names: List[str]) -> Optional[Path]:
    """
    - pathlib.Path.iterdir() ì‚¬ìš©
    - glob-only ë°©ì‹ ê¸ˆì§€ ì¤€ìˆ˜
    - íŒŒì¼ëª… f-string ì¡°í•© ê¸ˆì§€ (exact_names ë¦¬ìŠ¤íŠ¸ë¡œë§Œ ë¹„êµ)
    """
    if not folder.exists() or not folder.is_dir():
        return None

    for p in folder.iterdir():
        if not p.is_file():
            continue
        for name in exact_names:
            if _same_filename(p.name, name):
                return p
    return None


def best_match_sheet_name(sheet_names: List[str], school: str) -> Optional[str]:
    """
    ì‹œíŠ¸ëª… í•˜ë“œì½”ë”© ê¸ˆì§€:
    - ì—‘ì…€ ì‹¤ì œ sheet_namesì—ì„œ í•™êµëª… í¬í•¨(ì •ê·œí™” í¬í•¨) ì‹œíŠ¸ë¥¼ ì¶”ì • ë§¤ì¹­
    """
    school_vars = {_nfc(school), _nfd(school)}
    scored: List[Tuple[int, str]] = []

    for sh in sheet_names:
        sh_vars = {_nfc(sh), _nfd(sh)}
        hit = any((sv in hv) or (hv in sv) for sv in school_vars for hv in sh_vars)
        if not hit:
            continue
        # ì§§ê³  ëª…í™•í•œ ì‹œíŠ¸ëª… ì„ í˜¸
        score = 1000 - len(_nfc(sh))
        scored.append((score, sh))

    if not scored:
        return None

    scored.sort(key=lambda x: x[0], reverse=True)
    return scored[0][1]


# =============================
# Data loading (cached)
# =============================
@st.cache_data(show_spinner=False)
def load_env_csv(path: Path) -> pd.DataFrame:
    df = pd.read_csv(path)

    missing = [c for c in ENV_REQUIRED_COLS if c not in df.columns]
    if missing:
        raise ValueError(f"í™˜ê²½ CSVì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing}")

    df = df.copy()
    df["time"] = pd.to_datetime(df["time"], errors="coerce")
    df = df.dropna(subset=["time"]).sort_values("time")

    for col in ["temperature", "humidity", "ph", "ec"]:
        df[col] = pd.to_numeric(df[col], errors="coerce")

    # í•µì‹¬ ê°’ì´ ë¹„ì–´ìˆìœ¼ë©´ ì œê±°
    df = df.dropna(subset=["temperature", "humidity", "ph", "ec"])
    return df


@st.cache_data(show_spinner=False)
def load_growth_xlsx_all_sheets(path: Path) -> Dict[str, pd.DataFrame]:
    # ì‹œíŠ¸ëª… í•˜ë“œì½”ë”© ê¸ˆì§€: sheet_name=Noneë¡œ ì „ì²´ ë¡œë”©
    data = pd.read_excel(path, sheet_name=None, engine="openpyxl")
    cleaned: Dict[str, pd.DataFrame] = {}

    for sheet, df in data.items():
        if df is None or df.empty:
            continue
        df = df.copy()
        if not all(c in df.columns for c in GROW_REQUIRED_COLS):
            continue

        for col in ["ì ìˆ˜(ì¥)", "ì§€ìƒë¶€ ê¸¸ì´(mm)", "ì§€í•˜ë¶€ê¸¸ì´(mm)", "ìƒì¤‘ëŸ‰(g)"]:
            df[col] = pd.to_numeric(df[col], errors="coerce")

        df = df.dropna(subset=["ìƒì¤‘ëŸ‰(g)"])
        cleaned[sheet] = df

    if not cleaned:
        raise ValueError("ì—‘ì…€ì—ì„œ ìœ íš¨í•œ ìƒìœ¡ ë°ì´í„° ì‹œíŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤(í•„ìˆ˜ ì»¬ëŸ¼ ë¶ˆì¼ì¹˜).")

    return cleaned


def df_to_csv_bytes(df: pd.DataFrame) -> bytes:
    return df.to_csv(index=False).encode("utf-8-sig")


def df_to_xlsx_buffer(df: pd.DataFrame, sheet_name: str = "data") -> io.BytesIO:
    """
    XLSX ë‹¤ìš´ë¡œë“œ: BytesIO + ExcelWriter(openpyxl) (í•„ìˆ˜ ìš”êµ¬ì‚¬í•­)
    """
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
        df.to_excel(writer, index=False, sheet_name=sheet_name)
    buffer.seek(0)
    return buffer


# =============================
# Preprocessing / filtering
# =============================
def iqr_filter(df: pd.DataFrame, cols: List[str], k: float = 1.5) -> pd.DataFrame:
    """
    ê·¹ë‹¨ê°’ ì œì™¸(IQR ê¸°ë°˜)
    - í™˜ê²½ë°ì´í„°: temp/humidity/ph/ec ë“±
    """
    out = df.copy()
    mask = pd.Series(True, index=out.index)
    for c in cols:
        if c not in out.columns:
            continue
        q1 = out[c].quantile(0.25)
        q3 = out[c].quantile(0.75)
        iqr = q3 - q1
        if pd.isna(iqr) or iqr == 0:
            continue
        low = q1 - k * iqr
        high = q3 + k * iqr
        mask = mask & out[c].between(low, high, inclusive="both")
    return out.loc[mask].copy()


def apply_env_filters(
    df: pd.DataFrame,
    use_ph_range: bool,
    ph_low: float,
    ph_high: float,
    drop_extremes: bool,
    iqr_k: float,
) -> Tuple[pd.DataFrame, Dict[str, int]]:
    """
    ë°˜í™˜:
      filtered_df, report(dict: before/after counts, excluded counts)
    """
    before = len(df)
    out = df.copy()

    excluded_ph = 0
    if use_ph_range:
        mask_ph = out["ph"].between(ph_low, ph_high, inclusive="both")
        excluded_ph = int((~mask_ph).sum())
        out = out.loc[mask_ph].copy()

    excluded_iqr = 0
    if drop_extremes:
        before_iqr = len(out)
        out = iqr_filter(out, cols=["temperature", "humidity", "ph", "ec"], k=iqr_k)
        excluded_iqr = before_iqr - len(out)

    after = len(out)
    return out, {"before": before, "after": after, "excluded_ph": excluded_ph, "excluded_iqr": excluded_iqr}


def apply_growth_outlier_filter(df: pd.DataFrame, drop_extremes: bool, iqr_k: float) -> Tuple[pd.DataFrame, int]:
    """
    ìƒìœ¡ ë°ì´í„°ëŠ” pH í•„í„°ê°€ ì—†ìœ¼ë¯€ë¡œ, ì„ íƒì ìœ¼ë¡œ ìƒì¤‘ëŸ‰ ê¸°ë°˜ IQR ì œê±°ë§Œ ì œê³µ.
    """
    if not drop_extremes:
        return df.copy(), 0
    before = len(df)
    out = iqr_filter(df, cols=["ìƒì¤‘ëŸ‰(g)"], k=iqr_k)
    return out, before - len(out)


# =============================
# Summaries
# =============================
def env_stats(df: pd.DataFrame) -> Dict[str, float]:
    return {
        "í‰ê· ": float(df.mean()),
        "ìµœì†Œ": float(df.min()),
        "ìµœëŒ€": float(df.max()),
    }


def make_env_summary(env_by_school: Dict[str, pd.DataFrame]) -> pd.DataFrame:
    rows = []
    for s, df in env_by_school.items():
        rows.append(
            {
                "í•™êµ": s,
                "ì¸¡ì • ì‹œì‘": df["time"].min(),
                "ì¸¡ì • ì¢…ë£Œ": df["time"].max(),
                "ë°ì´í„° ê°œìˆ˜": int(df.shape[0]),
                "ê²°ì¸¡ì¹˜(í•„ìˆ˜ì—´ ê¸°ì¤€)": 0,  # ë¡œë”© ë‹¨ê³„ì—ì„œ í•„ìˆ˜ì—´ NaN ì œê±° í›„ë¼ 0ìœ¼ë¡œ ì •ì˜
                "í‰ê·  ì˜¨ë„": df["temperature"].mean(),
                "í‰ê·  ìŠµë„": df["humidity"].mean(),
                "í‰ê·  pH": df["ph"].mean(),
                "ì‹¤ì¸¡ í‰ê·  EC": df["ec"].mean(),
                "ì‹¤ì¸¡ EC ë³€ë™(í‘œì¤€í¸ì°¨)": df["ec"].std(),
            }
        )
    out = pd.DataFrame(rows)
    out["í•™êµ"] = pd.Categorical(out["í•™êµ"], categories=SCHOOLS, ordered=True)
    out = out.sort_values("í•™êµ")
    return out


def make_env_minmax_table(env_by_school: Dict[str, pd.DataFrame]) -> pd.DataFrame:
    rows = []
    for s, df in env_by_school.items():
        rows.append(
            {
                "í•™êµ": s,
                "ì˜¨ë„ í‰ê· ": df["temperature"].mean(),
                "ì˜¨ë„ ìµœì†Œ": df["temperature"].min(),
                "ì˜¨ë„ ìµœëŒ€": df["temperature"].max(),
                "ìŠµë„ í‰ê· ": df["humidity"].mean(),
                "ìŠµë„ ìµœì†Œ": df["humidity"].min(),
                "ìŠµë„ ìµœëŒ€": df["humidity"].max(),
                "pH í‰ê· ": df["ph"].mean(),
                "pH ìµœì†Œ": df["ph"].min(),
                "pH ìµœëŒ€": df["ph"].max(),
                "EC í‰ê· ": df["ec"].mean(),
                "EC ìµœì†Œ": df["ec"].min(),
                "EC ìµœëŒ€": df["ec"].max(),
            }
        )
    out = pd.DataFrame(rows)
    out["í•™êµ"] = pd.Categorical(out["í•™êµ"], categories=SCHOOLS, ordered=True)
    out = out.sort_values("í•™êµ")
    return out


def make_growth_summary(growth_by_school: Dict[str, pd.DataFrame]) -> pd.DataFrame:
    rows = []
    for s, df in growth_by_school.items():
        rows.append(
            {
                "í•™êµ": s,
                "EC ì¡°ê±´(ì„¤ì •)": SCHOOL_EC_TARGET.get(s, None),
                "ê°œì²´ìˆ˜(n)": int(df.shape[0]),
                "í‰ê·  ìƒì¤‘ëŸ‰(g)": df["ìƒì¤‘ëŸ‰(g)"].mean(),
                "í‰ê·  ì ìˆ˜(ì¥)": df["ì ìˆ˜(ì¥)"].mean(),
                "í‰ê·  ì§€ìƒë¶€ ê¸¸ì´(mm)": df["ì§€ìƒë¶€ ê¸¸ì´(mm)"].mean(),
            }
        )
    out = pd.DataFrame(rows)
    out["í•™êµ"] = pd.Categorical(out["í•™êµ"], categories=SCHOOLS, ordered=True)
    out = out.sort_values("í•™êµ")
    return out


def best_ec_by_weight(growth_summary: pd.DataFrame) -> Tuple[float, str, float]:
    idx = growth_summary["í‰ê·  ìƒì¤‘ëŸ‰(g)"].idxmax()
    row = growth_summary.loc[idx]
    return float(row["EC ì¡°ê±´(ì„¤ì •)"]), str(row["í•™êµ"]), float(row["í‰ê·  ìƒì¤‘ëŸ‰(g)"])


# =============================
# File structure + load all
# =============================
BASE_DIR = Path(__file__).resolve().parent
DATA_DIR = BASE_DIR / "data"

# ì •í™• íŒŒì¼ëª…(ìš”êµ¬ êµ¬ì¡°)
CSV_NAME_CANDIDATES: Dict[str, List[str]] = {
    "ì†¡ë„ê³ ": ["ì†¡ë„ê³ _í™˜ê²½ë°ì´í„°.csv"],
    "í•˜ëŠ˜ê³ ": ["í•˜ëŠ˜ê³ _í™˜ê²½ë°ì´í„°.csv"],
    "ì•„ë¼ê³ ": ["ì•„ë¼ê³ _í™˜ê²½ë°ì´í„°.csv"],
    "ë™ì‚°ê³ ": ["ë™ì‚°ê³ _í™˜ê²½ë°ì´í„°.csv"],
}
XLSX_NAME_CANDIDATES = ["4ê°œêµ_ìƒìœ¡ê²°ê³¼ë°ì´í„°.xlsx"]


@st.cache_data(show_spinner=False)
def load_all_raw() -> Tuple[Dict[str, pd.DataFrame], Dict[str, pd.DataFrame], Path, Dict[str, Path]]:
    if not DATA_DIR.exists():
        raise FileNotFoundError(f"data í´ë”ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {DATA_DIR}")

    env_by_school: Dict[str, pd.DataFrame] = {}
    csv_paths: Dict[str, Path] = {}

    for school in SCHOOLS:
        p = find_file_by_exact_names(DATA_DIR, CSV_NAME_CANDIDATES[school])
        if p is None:
            existing = [q.name for q in DATA_DIR.iterdir() if q.is_file()]
            raise FileNotFoundError(
                f"í™˜ê²½ ë°ì´í„° íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {CSV_NAME_CANDIDATES[school]}\n"
                f"- data í´ë” íŒŒì¼ ëª©ë¡: {existing}"
            )
        csv_paths[school] = p
        env_by_school[school] = load_env_csv(p)

    xlsx_path = find_file_by_exact_names(DATA_DIR, XLSX_NAME_CANDIDATES)
    if xlsx_path is None:
        existing = [q.name for q in DATA_DIR.iterdir() if q.is_file()]
        raise FileNotFoundError(
            f"ìƒìœ¡ ê²°ê³¼ ì—‘ì…€ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {XLSX_NAME_CANDIDATES}\n"
            f"- data í´ë” íŒŒì¼ ëª©ë¡: {existing}"
        )

    sheets = load_growth_xlsx_all_sheets(xlsx_path)
    sheet_names = list(sheets.keys())

    growth_by_school: Dict[str, pd.DataFrame] = {}
    for school in SCHOOLS:
        matched = best_match_sheet_name(sheet_names, school)
        if matched is None:
            raise FileNotFoundError(
                f"ì—‘ì…€ ì‹œíŠ¸ ì¤‘ '{school}'ì— í•´ë‹¹í•˜ëŠ” ì‹œíŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n"
                f"- í˜„ì¬ ìœ íš¨ ì‹œíŠ¸: {sheet_names}"
            )
        growth_by_school[school] = sheets[matched].copy()

    return env_by_school, growth_by_school, xlsx_path, csv_paths


def build_filtered_views(
    env_raw: Dict[str, pd.DataFrame],
    growth_raw: Dict[str, pd.DataFrame],
    use_ph_range: bool,
    ph_low: float,
    ph_high: float,
    drop_env_extremes: bool,
    drop_growth_extremes: bool,
    iqr_k: float,
) -> Tuple[Dict[str, pd.DataFrame], Dict[str, pd.DataFrame], pd.DataFrame]:
    """
    ë°˜í™˜:
      env_filtered_by_school, growth_filtered_by_school, filter_report_df
    """
    env_filtered: Dict[str, pd.DataFrame] = {}
    growth_filtered: Dict[str, pd.DataFrame] = {}
    report_rows = []

    for s in SCHOOLS:
        df_env_f, rep = apply_env_filters(
            env_raw[s],
            use_ph_range=use_ph_range,
            ph_low=ph_low,
            ph_high=ph_high,
            drop_extremes=drop_env_extremes,
            iqr_k=iqr_k,
        )
        env_filtered[s] = df_env_f

        df_g_f, excluded_g = apply_growth_outlier_filter(
            growth_raw[s],
            drop_extremes=drop_growth_extremes,
            iqr_k=iqr_k,
        )
        growth_filtered[s] = df_g_f

        report_rows.append(
            {
                "í•™êµ": s,
                "í™˜ê²½ ë°ì´í„°(ì „)": rep["before"],
                "í™˜ê²½ ë°ì´í„°(í›„)": rep["after"],
                "í™˜ê²½ ì œì™¸(pHë²”ìœ„)": rep["excluded_ph"],
                "í™˜ê²½ ì œì™¸(IQR)": rep["excluded_iqr"],
                "ìƒìœ¡ ë°ì´í„°(ì „)": int(growth_raw[s].shape[0]),
                "ìƒìœ¡ ë°ì´í„°(í›„)": int(df_g_f.shape[0]),
                "ìƒìœ¡ ì œì™¸(IQR, ìƒì¤‘ëŸ‰)": int(excluded_g),
            }
        )

    report_df = pd.DataFrame(report_rows)
    report_df["í•™êµ"] = pd.Categorical(report_df["í•™êµ"], categories=SCHOOLS, ordered=True)
    report_df = report_df.sort_values("í•™êµ")
    return env_filtered, growth_filtered, report_df


# =============================
# Sidebar controls
# =============================
st.title("ğŸŒ± ê·¹ì§€ì‹ë¬¼ ìµœì  EC ë†ë„ ì—°êµ¬")

with st.sidebar:
    st.header("ì„¤ì •")

    school_option = st.selectbox("í•™êµ ì„ íƒ", ["ì „ì²´"] + SCHOOLS, index=0)

    st.markdown("---")
    st.subheader("ì „ì²˜ë¦¬(ì‹ ë¢°ë„ ì ê²€)")

    use_ph_range = st.checkbox("pH 5~7 ë²”ìœ„ë§Œ ì‚¬ìš©", value=True)
    ph_low, ph_high = 5.0, 7.0

    drop_env_extremes = st.checkbox("í™˜ê²½ ë°ì´í„° ê·¹ë‹¨ê°’ ì œì™¸(IQR)", value=False)
    drop_growth_extremes = st.checkbox("ìƒìœ¡ ë°ì´í„° ê·¹ë‹¨ê°’ ì œì™¸(ìƒì¤‘ëŸ‰ IQR)", value=False)
    iqr_k = st.slider("IQR ë°°ìˆ˜(k)", min_value=1.0, max_value=3.0, value=1.5, step=0.1)

    st.caption("í•´ì„ ê¸°ì¤€: ì¸¡ì • ì£¼ê¸° ì°¨ì´ê°€ ìˆìœ¼ë¯€ë¡œ ë™ì¼ ì‹œê°„ ê°„ê²© ë¹„êµê°€ ì•„ë‹ˆë¼ í•™êµë³„ ìš”ì•½ í†µê³„ ì¤‘ì‹¬ìœ¼ë¡œ ë¹„êµí•©ë‹ˆë‹¤.")


# =============================
# Load data
# =============================
try:
    with st.spinner("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
        env_raw_by_school, growth_raw_by_school, xlsx_path, csv_paths = load_all_raw()

        env_f_by_school, growth_f_by_school, filter_report = build_filtered_views(
            env_raw=env_raw_by_school,
            growth_raw=growth_raw_by_school,
            use_ph_range=use_ph_range,
            ph_low=ph_low,
            ph_high=ph_high,
            drop_env_extremes=drop_env_extremes,
            drop_growth_extremes=drop_growth_extremes,
            iqr_k=iqr_k,
        )
except Exception as e:
    st.error(f"ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\n- ì›ì¸: {e}")
    st.stop()

selected_schools = SCHOOLS if school_option == "ì „ì²´" else [school_option]

# ìš”ì•½ í…Œì´ë¸”(í•„í„° ì ìš©ë³¸)
env_summary = make_env_summary(env_f_by_school)
env_minmax = make_env_minmax_table(env_f_by_school)
growth_summary = make_growth_summary(growth_f_by_school)

best_ec_data, best_school_data, best_weight_data = best_ec_by_weight(growth_summary)

# ê¸°ëŒ€ ìµœì (ê°€ì„¤) í‘œê¸°: í•˜ëŠ˜ê³  EC 4.0
expected_best_school = "í•˜ëŠ˜ê³ "
expected_best_ec = SCHOOL_EC_TARGET.get(expected_best_school, None)


# =============================
# Tabs
# =============================
tab1, tab2, tab3 = st.tabs(
    [
        "ğŸ“–ë°ì´í„° ê°œìš” ë° ì‹ ë¢°ë„(ì „ì²˜ë¦¬)",
        "ğŸŒ¡ï¸ í™˜ê²½â€“ìƒìœ¡ í†µí•© ë¶„ì„(í•µì‹¬ í™”ë©´)",
        "ğŸ“Š ECë³„ ìƒìœ¡ ë¹„êµ ë° ë‹¤ìš´ë¡œë“œ(ê²°ê³¼ ê³µìœ )",
    ]
)


# =============================
# Tab 1: Data overview & reliability
# =============================
with tab1:
    st.subheader("ë°ì´í„° ì¶œì²˜/êµ¬ì„± ìš”ì•½")
    st.write(
        """
- í™˜ê²½ ë°ì´í„°: CSV 4ê°œ(í•™êµë³„), ì»¬ëŸ¼: time, temperature, humidity, ph, ec
- ìƒìœ¡ ê²°ê³¼: XLSX 1ê°œ(4ê°œ ì‹œíŠ¸), ì»¬ëŸ¼: ê°œì²´ë²ˆí˜¸, ì ìˆ˜(ì¥), ì§€ìƒë¶€ ê¸¸ì´(mm), ì§€í•˜ë¶€ê¸¸ì´(mm), ìƒì¤‘ëŸ‰(g)
"""
    )

    st.subheader("í•™êµë³„ ì¸¡ì • ê¸°ê°„ / ë°ì´í„° ê°œìˆ˜ / ì „ì²˜ë¦¬ ì˜í–¥")
    st.dataframe(env_summary[["í•™êµ", "ì¸¡ì • ì‹œì‘", "ì¸¡ì • ì¢…ë£Œ", "ë°ì´í„° ê°œìˆ˜", "í‰ê·  ì˜¨ë„", "í‰ê·  ìŠµë„", "í‰ê·  pH", "ì‹¤ì¸¡ í‰ê·  EC", "ì‹¤ì¸¡ EC ë³€ë™(í‘œì¤€í¸ì°¨)"]], use_container_width=True)

    st.subheader("ì „ì²˜ë¦¬(ì‹ ë¢°ë„) ì œì™¸ ê¸°ì¤€ ëª…ì‹œ")
    cols = st.columns(3)
    cols[0].metric("pH ì‚¬ìš© ë²”ìœ„", "5.0 ~ 7.0" if use_ph_range else "ë¯¸ì ìš©")
    cols[1].metric("í™˜ê²½ ê·¹ë‹¨ê°’ ì œì™¸(IQR)", "ì ìš©" if drop_env_extremes else "ë¯¸ì ìš©")
    cols[2].metric("ìƒìœ¡ ê·¹ë‹¨ê°’ ì œì™¸(IQR)", "ì ìš©" if drop_growth_extremes else "ë¯¸ì ìš©")
    st.dataframe(filter_report, use_container_width=True)

    st.subheader("ECÂ·ì˜¨ë„Â·ìŠµë„ ìš”ì•½ í†µê³„(í‰ê· /ìµœì†Œ/ìµœëŒ€)")
    st.dataframe(env_minmax, use_container_width=True)

    st.subheader("ì„¤ì • EC vs ì‹¤ì¸¡ í‰ê·  EC (ê´€ë¦¬ ì•ˆì •ì„± í™•ì¸)")
    comp = env_summary[["í•™êµ", "ì‹¤ì¸¡ í‰ê·  EC", "ì‹¤ì¸¡ EC ë³€ë™(í‘œì¤€í¸ì°¨)"]].copy()
    comp["ì„¤ì • EC"] = comp["í•™êµ"].astype(str).map(SCHOOL_EC_TARGET)
    comp["ì°¨ì´(ì‹¤ì¸¡-ì„¤ì •)"] = comp["ì‹¤ì¸¡ í‰ê·  EC"] - comp["ì„¤ì • EC"]
    st.dataframe(comp[["í•™êµ", "ì„¤ì • EC", "ì‹¤ì¸¡ í‰ê·  EC", "ì°¨ì´(ì‹¤ì¸¡-ì„¤ì •)", "ì‹¤ì¸¡ EC ë³€ë™(í‘œì¤€í¸ì°¨)"]], use_container_width=True)

    st.caption("í•´ì„ í¬ì¸íŠ¸: ì„¤ì • ECì™€ ì‹¤ì¸¡ í‰ê·  ECì˜ ì°¨ì´ê°€ í¬ê±°ë‚˜, ì‹¤ì¸¡ EC ë³€ë™ì´ í° ê²½ìš° â€˜ê´€ë¦¬ ì•ˆì •ì„±â€™ ë¦¬ìŠ¤í¬ë¡œ í•´ì„í•©ë‹ˆë‹¤.")


# =============================
# Tab 2: Integrated analysis
# =============================
with tab2:
    st.subheader("í•™êµë³„ í™˜ê²½ í‰ê·  ë¹„êµ (ìš”ì•½ í†µê³„ ì¤‘ì‹¬)")

    env_view = env_summary[["í•™êµ", "í‰ê·  ì˜¨ë„", "í‰ê·  ìŠµë„", "í‰ê·  pH", "ì‹¤ì¸¡ í‰ê·  EC"]].copy()
    env_view["ëª©í‘œ EC(ì„¤ì •)"] = env_view["í•™êµ"].astype(str).map(SCHOOL_EC_TARGET)

    fig = make_subplots(
        rows=2,
        cols=2,
        subplot_titles=("í‰ê·  ì˜¨ë„", "í‰ê·  ìŠµë„", "í‰ê·  pH", "ëª©í‘œ EC vs ì‹¤ì¸¡ EC(í‰ê· )"),
        horizontal_spacing=0.12,
        vertical_spacing=0.15,
    )

    fig.add_trace(
        go.Bar(
            x=env_view["í•™êµ"],
            y=env_view["í‰ê·  ì˜¨ë„"],
            name="í‰ê·  ì˜¨ë„",
            marker_color=[SCHOOL_COLOR[str(s)] for s in env_view["í•™êµ"]],
        ),
        row=1,
        col=1,
    )

    fig.add_trace(
        go.Bar(
            x=env_view["í•™êµ"],
            y=env_view["í‰ê·  ìŠµë„"],
            name="í‰ê·  ìŠµë„",
            marker_color=[SCHOOL_COLOR[str(s)] for s in env_view["í•™êµ"]],
        ),
        row=1,
        col=2,
    )

    fig.add_trace(
        go.Bar(
            x=env_view["í•™êµ"],
            y=env_view["í‰ê·  pH"],
            name="í‰ê·  pH",
            marker_color=[SCHOOL_COLOR[str(s)] for s in env_view["í•™êµ"]],
        ),
        row=2,
        col=1,
    )

    fig.add_trace(go.Bar(x=env_view["í•™êµ"], y=env_view["ëª©í‘œ EC(ì„¤ì •)"], name="ëª©í‘œ EC", opacity=0.7), row=2, col=2)
    fig.add_trace(go.Bar(x=env_view["í•™êµ"], y=env_view["ì‹¤ì¸¡ í‰ê·  EC"], name="ì‹¤ì¸¡ í‰ê·  EC", opacity=0.7), row=2, col=2)

    fig.update_layout(
        barmode="group",
        height=720,
        font=dict(family=PLOTLY_FONT_FAMILY),
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
        margin=dict(l=40, r=40, t=80, b=40),
    )
    st.plotly_chart(fig, use_container_width=True)

    st.divider()
    st.subheader("ì„ íƒí•œ í•™êµ ì‹œê³„ì—´(ì˜¨ë„/ìŠµë„/EC)")

    if school_option == "ì „ì²´":
        st.info("í•™êµë³„ ì¸¡ì • ì£¼ê¸° ì°¨ì´ê°€ ìˆìœ¼ë¯€ë¡œ, ì „ì²´ ì„ íƒ ì‹œ í•™êµë³„ ì‹œê³„ì—´ì„ ê°ê° í‘œì‹œí•©ë‹ˆë‹¤.")
        for s in selected_schools:
            df = env_f_by_school[s]
            st.markdown(f"**{s}**")
            c1, c2, c3 = st.columns(3)

            fig_t = px.line(df, x="time", y="temperature", title="ì˜¨ë„ ë³€í™”")
            fig_t.update_layout(font=dict(family=PLOTLY_FONT_FAMILY), height=320)
            c1.plotly_chart(fig_t, use_container_width=True)

            fig_h = px.line(df, x="time", y="humidity", title="ìŠµë„ ë³€í™”")
            fig_h.update_layout(font=dict(family=PLOTLY_FONT_FAMILY), height=320)
            c2.plotly_chart(fig_h, use_container_width=True)

            fig_ec = px.line(df, x="time", y="ec", title="EC ë³€í™”(ëª©í‘œì„  í¬í•¨)")
            fig_ec.add_hline(y=SCHOOL_EC_TARGET[s], line_dash="dash")
            fig_ec.update_layout(font=dict(family=PLOTLY_FONT_FAMILY), height=320)
            c3.plotly_chart(fig_ec, use_container_width=True)
    else:
        s = school_option
        df = env_f_by_school[s]
        c1, c2, c3 = st.columns(3)

        fig_t = px.line(df, x="time", y="temperature", title="ì˜¨ë„ ë³€í™”")
        fig_t.update_layout(font=dict(family=PLOTLY_FONT_FAMILY), height=360)
        c1.plotly_chart(fig_t, use_container_width=True)

        fig_h = px.line(df, x="time", y="humidity", title="ìŠµë„ ë³€í™”")
        fig_h.update_layout(font=dict(family=PLOTLY_FONT_FAMILY), height=360)
        c2.plotly_chart(fig_h, use_container_width=True)

        fig_ec = px.line(df, x="time", y="ec", title="EC ë³€í™”(ëª©í‘œì„  í¬í•¨)")
        fig_ec.add_hline(y=SCHOOL_EC_TARGET[s], line_dash="dash")
        fig_ec.update_layout(font=dict(family=PLOTLY_FONT_FAMILY), height=360)
        c3.plotly_chart(fig_ec, use_container_width=True)

    st.divider()
    st.subheader("ECâ€“ì˜¨ë„â€“ìƒì¤‘ëŸ‰ í†µí•© ì‚°ì ë„(ìƒì¤‘ëŸ‰ ì¤‘ì‹¬)")

    # í•™êµë³„ í™˜ê²½ í‰ê·  + ìƒìœ¡ í‰ê· ì„ ë³‘í•©(ìš”ì•½ í†µê³„ ê¸°ë°˜)
    comb = env_summary[["í•™êµ", "í‰ê·  ì˜¨ë„", "ì‹¤ì¸¡ í‰ê·  EC"]].merge(
        growth_summary[["í•™êµ", "í‰ê·  ìƒì¤‘ëŸ‰(g)"]], on="í•™êµ", how="inner"
    )
    comb["ì„¤ì • EC"] = comb["í•™êµ"].astype(str).map(SCHOOL_EC_TARGET)

    fig_combo = px.scatter(
        comb,
        x="ì‹¤ì¸¡ í‰ê·  EC",
        y="í‰ê·  ì˜¨ë„",
        size="í‰ê·  ìƒì¤‘ëŸ‰(g)",
        color="í‰ê·  ìƒì¤‘ëŸ‰(g)",
        hover_name="í•™êµ",
        title="í•™êµë³„ (ì‹¤ì¸¡ í‰ê·  EC, í‰ê·  ì˜¨ë„) í‰ë©´ì—ì„œ ìƒì¤‘ëŸ‰(í¬ê¸°/ìƒ‰) í‘œí˜„",
    )
    fig_combo.update_layout(font=dict(family=PLOTLY_FONT_FAMILY), height=520)
    st.plotly_chart(fig_combo, use_container_width=True)

    st.subheader("ìƒê´€ê´€ê³„ í•´ì„(ì¡°í•© íš¨ê³¼ ì¤‘ì‹¬)")
    # ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì¥ ìƒì„±(ê³¼ë„í•œ ë‹¨ì • ë°©ì§€)
    best_by_data_txt = f"ë°ì´í„° ê¸°ì¤€ ìµœëŒ€ í‰ê·  ìƒì¤‘ëŸ‰ì€ {best_school_data}(ì„¤ì • EC {best_ec_data:.1f})ì—ì„œ ê´€ì°°ë˜ì—ˆìŠµë‹ˆë‹¤."
    expected_txt = f"ê°€ì„¤(ê¸°ëŒ€ ìµœì )ì€ {expected_best_school}(ì„¤ì • EC {expected_best_ec:.1f})ë¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤."

    # ê°„ë‹¨ ë¦¬ìŠ¤í¬ ë¬¸ì¥(ì‹¤ì¸¡ EC ì•ˆì •ì„±)
    comp2 = env_summary.copy()
    comp2["ì„¤ì • EC"] = comp2["í•™êµ"].astype(str).map(SCHOOL_EC_TARGET)
    comp2["|ì‹¤ì¸¡-ì„¤ì •|"] = (comp2["ì‹¤ì¸¡ í‰ê·  EC"] - comp2["ì„¤ì • EC"]).abs()
    worst_school = str(comp2.sort_values("|ì‹¤ì¸¡-ì„¤ì •|", ascending=False).iloc[0]["í•™êµ"])
    worst_gap = float(comp2.sort_values("|ì‹¤ì¸¡-ì„¤ì •|", ascending=False).iloc[0]["|ì‹¤ì¸¡-ì„¤ì •|"])

    st.write(
        f"""
- {expected_txt}
- {best_by_data_txt}
- ì¡°í•© íš¨ê³¼ í•´ì„ì€ â€œEC ë‹¨ë…â€ì´ ì•„ë‹ˆë¼ **(ì‹¤ì¸¡ EC Ã— í‰ê·  ì˜¨ë„)**ì—ì„œ ìƒì¤‘ëŸ‰ì´ í¬ê²Œ ë‚˜íƒ€ë‚˜ëŠ” ì§€ì ì„ ì¤‘ì‹¬ìœ¼ë¡œ íŒë‹¨í•©ë‹ˆë‹¤.
- ê´€ë¦¬ ì•ˆì •ì„± ê´€ì ì—ì„œ, ì„¤ì • EC ëŒ€ë¹„ ì‹¤ì¸¡ í‰ê·  EC í¸ì°¨ê°€ ê°€ì¥ í° í•™êµëŠ” **{worst_school} (í¸ì°¨ |Î”EC|â‰ˆ{worst_gap:.2f})**ë¡œ í™•ì¸ë©ë‹ˆë‹¤.
"""
    )

    st.subheader("í•„ìš” ì‹œ: íˆíŠ¸ë§µ(ì˜¨ë„ êµ¬ê°„ Ã— EC êµ¬ê°„) ìš”ì•½")
    # í•™êµë³„ ì (4ê°œ)ë§Œ ìˆìœ¼ë¯€ë¡œ "ì»¤ë²„ë¦¬ì§€+í‰ê·  ìƒì¤‘ëŸ‰" í˜•íƒœì˜ ìš”ì•½ íˆíŠ¸ë§µ ì œê³µ
    # êµ¬ê°„ì€ ê³¼ë„í•˜ê²Œ ì„¸ë¶„í™”í•˜ì§€ ì•ŠìŒ(ë°ì´í„° í¬ì†Œì„± ê³ ë ¤)
    temp_bins = pd.IntervalIndex.from_tuples([(0, 10), (10, 15), (15, 20), (20, 25), (25, 35)], closed="left")
    ec_bins = pd.IntervalIndex.from_tuples([(0, 1.5), (1.5, 3.0), (3.0, 5.0), (5.0, 9.0)], closed="left")

    hm = comb.copy()
    hm["ì˜¨ë„ êµ¬ê°„"] = pd.cut(hm["í‰ê·  ì˜¨ë„"], bins=temp_bins)
    hm["EC êµ¬ê°„"] = pd.cut(hm["ì‹¤ì¸¡ í‰ê·  EC"], bins=ec_bins)

    pivot = hm.pivot_table(index="ì˜¨ë„ êµ¬ê°„", columns="EC êµ¬ê°„", values="í‰ê·  ìƒì¤‘ëŸ‰(g)", aggfunc="mean")

    # Plotly heatmap
    fig_hm = go.Figure(
        data=go.Heatmap(
            z=pivot.values,
            x=[str(c) for c in pivot.columns],
            y=[str(i) for i in pivot.index],
            hoverongaps=False,
        )
    )
    fig_hm.update_layout(
        title="(í¬ì†Œ ë°ì´í„°) ì˜¨ë„ êµ¬ê°„ Ã— ì‹¤ì¸¡ EC êµ¬ê°„ë³„ í‰ê·  ìƒì¤‘ëŸ‰ ìš”ì•½",
        font=dict(family=PLOTLY_FONT_FAMILY),
        height=420,
        xaxis_title="ì‹¤ì¸¡ EC êµ¬ê°„",
        yaxis_title="í‰ê·  ì˜¨ë„ êµ¬ê°„",
        margin=dict(l=40, r=40, t=60, b=40),
    )
    st.plotly_chart(fig_hm, use_container_width=True)
    st.caption("ì£¼ì˜: í•™êµ ë‹¨ìœ„(4ì ) ìš”ì•½ì´ë¯€ë¡œ ë¹ˆ êµ¬ê°„ì´ ë§ìŠµë‹ˆë‹¤. â€˜ë¹„ì–´ ìˆëŠ” ì˜¨ë„â€“EC ì˜ì—­â€™ì„ í™•ì¸í•˜ëŠ” ëª©ì ì— ì í•©í•©ë‹ˆë‹¤.")

    with st.expander("í™˜ê²½ ë°ì´í„° ì›ë³¸/í•„í„° ê²°ê³¼ í…Œì´ë¸” + CSV ë‹¤ìš´ë¡œë“œ"):
        mode = st.radio("í‘œì‹œ ë°ì´í„°", ["í•„í„° ì ìš©ë³¸", "ì›ë³¸(í•„í„° ë¯¸ì ìš©)"], horizontal=True)
        env_view_dict = env_f_by_school if mode == "í•„í„° ì ìš©ë³¸" else env_raw_by_school

        if school_option == "ì „ì²´":
            for s in SCHOOLS:
                st.markdown(f"**{s}**  (íŒŒì¼: {csv_paths[s].name})")
                st.dataframe(env_view_dict[s], use_container_width=True)
                st.download_button(
                    label=f"{s} CSV ë‹¤ìš´ë¡œë“œ({mode})",
                    data=df_to_csv_bytes(env_view_dict[s]),
                    file_name=f"{s}_í™˜ê²½ë°ì´í„°_{'í•„í„°' if mode=='í•„í„° ì ìš©ë³¸' else 'ì›ë³¸'}.csv",
                    mime="text/csv",
                )
        else:
            s = school_option
            st.markdown(f"**{s}**  (íŒŒì¼: {csv_paths[s].name})")
            st.dataframe(env_view_dict[s], use_container_width=True)
            st.download_button(
                label=f"{s} CSV ë‹¤ìš´ë¡œë“œ({mode})",
                data=df_to_csv_bytes(env_view_dict[s]),
                file_name=f"{s}_í™˜ê²½ë°ì´í„°_{'í•„í„°' if mode=='í•„í„° ì ìš©ë³¸' else 'ì›ë³¸'}.csv",
                mime="text/csv",
            )


# =============================
# Tab 3: Growth comparison & downloads
# =============================
with tab3:
    st.subheader("ğŸ¥‡ í•µì‹¬ ê²°ê³¼(ìƒì¤‘ëŸ‰ ìµœìš°ì„ ): EC ì¡°ê±´ë³„ í‰ê·  ìƒì¤‘ëŸ‰")

    # ê²°ê³¼ ì¹´ë“œ: ë°ì´í„° ê¸°ë°˜ ìµœì  vs ê¸°ëŒ€ ìµœì (ê°€ì„¤)
    c1, c2, c3 = st.columns(3)
    c1.metric("ë°ì´í„° ê¸°ë°˜ ìµœì (í‰ê·  ìƒì¤‘ëŸ‰ ìµœëŒ€)", f"EC {best_ec_data:.1f}", f"{best_school_data} / {best_weight_data:.3f} g")

    if expected_best_ec is not None:
        # ê¸°ëŒ€ ìµœì (í•˜ëŠ˜ê³ ) ê²°ê³¼ë„ í•¨ê»˜ í‘œì‹œ(ë‹¨ì • ë°©ì§€)
        exp_row = growth_summary[growth_summary["í•™êµ"].astype(str) == expected_best_school]
        if not exp_row.empty:
            exp_w = float(exp_row.iloc[0]["í‰ê·  ìƒì¤‘ëŸ‰(g)"])
            c2.metric("ê°€ì„¤(ê¸°ëŒ€ ìµœì )", f"{expected_best_school} / EC {expected_best_ec:.1f}", f"{exp_w:.3f} g")
        else:
            c2.metric("ê°€ì„¤(ê¸°ëŒ€ ìµœì )", f"{expected_best_school} / EC {expected_best_ec:.1f}", "ìƒìœ¡ ì‹œíŠ¸ ë§¤ì¹­ í•„ìš”")
    else:
        c2.metric("ê°€ì„¤(ê¸°ëŒ€ ìµœì )", "ë¯¸ì§€ì •", "")

    c3.metric("ì „ì²˜ë¦¬ ì˜í–¥(ìš”ì•½)", "pH í•„í„°" if use_ph_range else "ë¯¸ì ìš©", "IQR ì œì™¸ ì ìš©" if (drop_env_extremes or drop_growth_extremes) else "IQR ë¯¸ì ìš©")

    # EC ì¡°ê±´ ìˆœì„œ(1.0,2.0,4.0,8.0)ë¡œ ì •ë ¬
    gs = growth_summary.copy()
    gs["EC ì¡°ê±´(ì„¤ì •)"] = pd.to_numeric(gs["EC ì¡°ê±´(ì„¤ì •)"], errors="coerce")
    gs = gs.sort_values("EC ì¡°ê±´(ì„¤ì •)")

    # ë§‰ëŒ€: í‰ê·  ìƒì¤‘ëŸ‰(ê°€ì¥ ì¤‘ìš”) - í•˜ëŠ˜ê³ (ê¸°ëŒ€ ìµœì ) ê°•ì¡°ë¥¼ ìœ„í•´ í…Œë‘ë¦¬/ì£¼ì„(ìƒ‰ì€ í•™êµìƒ‰)
    bar_colors = [SCHOOL_COLOR[str(s)] for s in gs["í•™êµ"].astype(str)]

    fig_w = go.Figure()
    fig_w.add_trace(
        go.Bar(
            x=gs["EC ì¡°ê±´(ì„¤ì •)"].astype(str),
            y=gs["í‰ê·  ìƒì¤‘ëŸ‰(g)"],
            text=gs["í•™êµ"].astype(str),
            marker_color=bar_colors,
        )
    )
    fig_w.update_layout(
        title="EC ì¡°ê±´ë³„ í‰ê·  ìƒì¤‘ëŸ‰(í•™êµë³„ ì¡°ê±´)",
        xaxis_title="EC ì¡°ê±´(ì„¤ì •)",
        yaxis_title="í‰ê·  ìƒì¤‘ëŸ‰(g)",
        font=dict(family=PLOTLY_FONT_FAMILY),
        height=420,
    )

    # ê¸°ëŒ€ ìµœì (í•˜ëŠ˜ê³ ) ì£¼ì„ í‘œì‹œ
    try:
        idx_h = gs.index[gs["í•™êµ"].astype(str) == expected_best_school][0]
        x_h = str(gs.loc[idx_h, "EC ì¡°ê±´(ì„¤ì •)"])
        y_h = float(gs.loc[idx_h, "í‰ê·  ìƒì¤‘ëŸ‰(g)"])
        fig_w.add_annotation(
            x=x_h,
            y=y_h,
            text="ê¸°ëŒ€ ìµœì (ê°€ì„¤)",
            showarrow=True,
            arrowhead=2,
            yshift=15,
        )
    except Exception:
        pass

    st.plotly_chart(fig_w, use_container_width=True)

    st.divider()
    st.subheader("ECë³„ ìƒìœ¡ ë¹„êµ (2x2)")

    fig2 = make_subplots(
        rows=2,
        cols=2,
        subplot_titles=("í‰ê·  ìƒì¤‘ëŸ‰(g) â­", "í‰ê·  ì ìˆ˜(ì¥)", "í‰ê·  ì§€ìƒë¶€ ê¸¸ì´(mm)", "ê°œì²´ìˆ˜ ë¹„êµ"),
        horizontal_spacing=0.12,
        vertical_spacing=0.15,
    )

    fig2.add_trace(go.Bar(x=gs["EC ì¡°ê±´(ì„¤ì •)"].astype(str), y=gs["í‰ê·  ìƒì¤‘ëŸ‰(g)"]), row=1, col=1)
    fig2.add_trace(go.Bar(x=gs["EC ì¡°ê±´(ì„¤ì •)"].astype(str), y=gs["í‰ê·  ì ìˆ˜(ì¥)"]), row=1, col=2)
    fig2.add_trace(go.Bar(x=gs["EC ì¡°ê±´(ì„¤ì •)"].astype(str), y=gs["í‰ê·  ì§€ìƒë¶€ ê¸¸ì´(mm)"]), row=2, col=1)
    fig2.add_trace(go.Bar(x=gs["EC ì¡°ê±´(ì„¤ì •)"].astype(str), y=gs["ê°œì²´ìˆ˜(n)"]), row=2, col=2)

    fig2.update_layout(
        height=720,
        font=dict(family=PLOTLY_FONT_FAMILY),
        showlegend=False,
        margin=dict(l=40, r=40, t=80, b=40),
    )
    st.plotly_chart(fig2, use_container_width=True)

    st.divider()
    st.subheader("ë¶„í¬(í¸ì°¨Â·ì´ìƒì¹˜): í•™êµë³„ ìƒì¤‘ëŸ‰ ë¶„í¬")

    dist_rows = []
    for s in selected_schools:
        df = growth_f_by_school[s].copy()
        df["í•™êµ"] = s
        df["EC ì¡°ê±´(ì„¤ì •)"] = SCHOOL_EC_TARGET[s]
        dist_rows.append(df)
    dist_df = pd.concat(dist_rows, ignore_index=True)

    fig_dist = px.violin(
        dist_df,
        x="í•™êµ",
        y="ìƒì¤‘ëŸ‰(g)",
        box=True,
        points="all",
        title="í•™êµë³„ ìƒì¤‘ëŸ‰ ë¶„í¬(ë°”ì´ì˜¬ë¦°+ë°•ìŠ¤)",
    )
    fig_dist.update_layout(font=dict(family=PLOTLY_FONT_FAMILY), height=520)
    st.plotly_chart(fig_dist, use_container_width=True)

    st.divider()
    st.subheader("ìƒê´€ê´€ê³„ ë¶„ì„(ì‚°ì ë„ 2ê°œ)")

    c1, c2 = st.columns(2)

    fig_sc1 = px.scatter(dist_df, x="ì ìˆ˜(ì¥)", y="ìƒì¤‘ëŸ‰(g)", color="í•™êµ", title="ì ìˆ˜ vs ìƒì¤‘ëŸ‰")
    fig_sc1.update_layout(font=dict(family=PLOTLY_FONT_FAMILY), height=480)
    c1.plotly_chart(fig_sc1, use_container_width=True)

    fig_sc2 = px.scatter(dist_df, x="ì§€ìƒë¶€ ê¸¸ì´(mm)", y="ìƒì¤‘ëŸ‰(g)", color="í•™êµ", title="ì§€ìƒë¶€ ê¸¸ì´ vs ìƒì¤‘ëŸ‰")
    fig_sc2.update_layout(font=dict(family=PLOTLY_FONT_FAMILY), height=480)
    c2.plotly_chart(fig_sc2, use_container_width=True)

    st.divider()
    st.subheader("í›„ì† ì‹¤í—˜ ì œì•ˆ(ë¹„ì–´ ìˆëŠ” ì˜¨ë„â€“EC ì˜ì—­ ê¸°ë°˜)")

    # íˆíŠ¸ë§µì—ì„œ ê´€ì¸¡ëœ êµ¬ê°„ë§Œ í‘œì‹œí•´ â€œë¹ˆ êµ¬ê°„â€ì„ ê°„ë‹¨ ìš”ì•½
    comb2 = env_summary[["í•™êµ", "í‰ê·  ì˜¨ë„", "ì‹¤ì¸¡ í‰ê·  EC"]].merge(
        growth_summary[["í•™êµ", "í‰ê·  ìƒì¤‘ëŸ‰(g)"]], on="í•™êµ", how="inner"
    )
    comb2["ì˜¨ë„ êµ¬ê°„"] = pd.cut(comb2["í‰ê·  ì˜¨ë„"], bins=[0, 10, 15, 20, 25, 35], right=False)
    comb2["EC êµ¬ê°„"] = pd.cut(comb2["ì‹¤ì¸¡ í‰ê·  EC"], bins=[0, 1.5, 3.0, 5.0, 9.0], right=False)

    observed_bins = comb2[["ì˜¨ë„ êµ¬ê°„", "EC êµ¬ê°„"]].dropna().drop_duplicates()

    st.write(
        """
- ëª©í‘œ: í˜„ì¬ ë°ì´í„°ì—ì„œ ìƒëŒ€ì ìœ¼ë¡œ ë¹„ì–´ ìˆëŠ” (ì˜¨ë„ Ã— EC) êµ¬ê°„ì„ ë³´ì™„í•˜ì—¬, **ì¡°í•© íš¨ê³¼(EC ë‹¨ë…ì´ ì•„ë‹Œ ECÃ—ì˜¨ë„)**ë¥¼ ë” ëª…í™•íˆ í™•ì¸í•©ë‹ˆë‹¤.
- ê¶Œì¥:
  - EC ì„¸ë¶„í™”: **1.5 ~ 3.0 êµ¬ê°„** ì¶”ê°€(ì¤‘ê°„ EC ì˜ì—­ì˜ ë°˜ì‘ í™•ì¸)
  - ì˜¨ë„ ë‹¨ê³„í™”: ë™ì¼ ECì—ì„œ **ì˜¨ë„ 2~3ë‹¨ê³„**(ì˜ˆ: 15â€“18â€“21Â°C ë“±)ë¡œ ë°˜ë³µ ì¸¡ì •
  - ë°˜ë³µìˆ˜/ê¸°ê°„ í™•ì¥: í‘œë³¸ ìˆ˜ì™€ ì¸¡ì • ê¸°ê°„ì„ ëŠ˜ë ¤ ë³€ë™ì„±(íŠ¹íˆ ì‹¤ì¸¡ EC ë³€ë™)ì„ ì•ˆì •ì ìœ¼ë¡œ ì¶”ì •
"""
    )

    st.caption(f"ê´€ì¸¡ëœ (ì˜¨ë„êµ¬ê°„Ã—ECêµ¬ê°„) ì¡°í•© ìˆ˜: {len(observed_bins)}ê°œ. ë¹„ì–´ ìˆëŠ” êµ¬ê°„ì„ ìš°ì„  ë³´ê°•í•˜ëŠ” ë°©ì‹ì´ íš¨ìœ¨ì ì…ë‹ˆë‹¤.")

    with st.expander("ì›ìë£Œ(í•„í„° ì ìš© ê²°ê³¼ í¬í•¨) í‘œ ì œê³µ ë° XLSX ë‹¤ìš´ë¡œë“œ"):
        mode = st.radio("í‘œì‹œ ë°ì´í„°", ["í•„í„° ì ìš©ë³¸", "ì›ë³¸(í•„í„° ë¯¸ì ìš©)"], horizontal=True, key="growth_mode")
        g_view = growth_f_by_school if mode == "í•„í„° ì ìš©ë³¸" else growth_raw_by_school

        if school_option == "ì „ì²´":
            for s in SCHOOLS:
                st.markdown(f"**{s} (EC {SCHOOL_EC_TARGET[s]:.1f})**")
                st.dataframe(g_view[s], use_container_width=True)

                buf = df_to_xlsx_buffer(g_view[s], sheet_name="ìƒìœ¡ë°ì´í„°")
                st.download_button(
                    label=f"{s} ìƒìœ¡ XLSX ë‹¤ìš´ë¡œë“œ({mode})",
                    data=buf,
                    file_name=f"{s}_ìƒìœ¡ë°ì´í„°_{'í•„í„°' if mode=='í•„í„° ì ìš©ë³¸' else 'ì›ë³¸'}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                )

            # ì›ë³¸ ì—‘ì…€(ì—…ë¡œë“œ íŒŒì¼ ê·¸ëŒ€ë¡œ) ë‹¤ìš´ë¡œë“œ
            try:
                raw_bytes = xlsx_path.read_bytes()
                st.download_button(
                    label="ì›ë³¸ 4ê°œêµ ìƒìœ¡ê²°ê³¼ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
                    data=raw_bytes,
                    file_name="4ê°œêµ_ìƒìœ¡ê²°ê³¼ë°ì´í„°.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                )
            except Exception as e:
                st.error(f"ì›ë³¸ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜: {e}")
        else:
            s = school_option
            st.markdown(f"**{s} (EC {SCHOOL_EC_TARGET[s]:.1f})**")
            st.dataframe(g_view[s], use_container_width=True)

            buf = df_to_xlsx_buffer(g_view[s], sheet_name="ìƒìœ¡ë°ì´í„°")
            st.download_button(
                label=f"{s} ìƒìœ¡ XLSX ë‹¤ìš´ë¡œë“œ({mode})",
                data=buf,
                file_name=f"{s}_ìƒìœ¡ë°ì´í„°_{'í•„í„°' if mode=='í•„í„° ì ìš©ë³¸' else 'ì›ë³¸'}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            )
